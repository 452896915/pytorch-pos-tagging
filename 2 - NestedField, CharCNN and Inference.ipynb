{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - NestedField, CharCNN and Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "WORDS = data.Field(lower=True)\n",
    "CHAR_NESTING = data.Field(tokenize=list, lower=True)\n",
    "CHARS = data.NestedField(CHAR_NESTING)\n",
    "UD_TAGS = data.Field(unk_token=None)\n",
    "PTB_TAGS = data.Field(unk_token=None)\n",
    "\n",
    "fields = [((\"words\", \"chars\"), (WORDS, CHARS)), (\"udtags\", UD_TAGS), (\"ptbtags\", PTB_TAGS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = datasets.UDPOS.splits(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 12543\n",
      "Number of validation examples: 2002\n",
      "Number of testing examples: 2077\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of training examples: {len(train_data)}\")\n",
    "print(f\"Number of validation examples: {len(valid_data)}\")\n",
    "print(f\"Number of testing examples: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'words': ['al', '-', 'zaman', ':', 'american', 'forces', 'killed', 'shaikh', 'abdullah', 'al', '-', 'ani', ',', 'the', 'preacher', 'at', 'the', 'mosque', 'in', 'the', 'town', 'of', 'qaim', ',', 'near', 'the', 'syrian', 'border', '.'], 'chars': [['a', 'l'], ['-'], ['z', 'a', 'm', 'a', 'n'], [':'], ['a', 'm', 'e', 'r', 'i', 'c', 'a', 'n'], ['f', 'o', 'r', 'c', 'e', 's'], ['k', 'i', 'l', 'l', 'e', 'd'], ['s', 'h', 'a', 'i', 'k', 'h'], ['a', 'b', 'd', 'u', 'l', 'l', 'a', 'h'], ['a', 'l'], ['-'], ['a', 'n', 'i'], [','], ['t', 'h', 'e'], ['p', 'r', 'e', 'a', 'c', 'h', 'e', 'r'], ['a', 't'], ['t', 'h', 'e'], ['m', 'o', 's', 'q', 'u', 'e'], ['i', 'n'], ['t', 'h', 'e'], ['t', 'o', 'w', 'n'], ['o', 'f'], ['q', 'a', 'i', 'm'], [','], ['n', 'e', 'a', 'r'], ['t', 'h', 'e'], ['s', 'y', 'r', 'i', 'a', 'n'], ['b', 'o', 'r', 'd', 'e', 'r'], ['.']], 'udtags': ['PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'ADJ', 'NOUN', 'VERB', 'PROPN', 'PROPN', 'PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'PROPN', 'PUNCT', 'ADP', 'DET', 'ADJ', 'NOUN', 'PUNCT'], 'ptbtags': ['NNP', 'HYPH', 'NNP', ':', 'JJ', 'NNS', 'VBD', 'NNP', 'NNP', 'NNP', 'HYPH', 'NNP', ',', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'NNP', ',', 'IN', 'DT', 'JJ', 'NN', '.']}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['al', '-', 'zaman', ':', 'american', 'forces', 'killed', 'shaikh', 'abdullah', 'al', '-', 'ani', ',', 'the', 'preacher', 'at', 'the', 'mosque', 'in', 'the', 'town', 'of', 'qaim', ',', 'near', 'the', 'syrian', 'border', '.']\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[0])['words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a', 'l'], ['-'], ['z', 'a', 'm', 'a', 'n'], [':'], ['a', 'm', 'e', 'r', 'i', 'c', 'a', 'n'], ['f', 'o', 'r', 'c', 'e', 's'], ['k', 'i', 'l', 'l', 'e', 'd'], ['s', 'h', 'a', 'i', 'k', 'h'], ['a', 'b', 'd', 'u', 'l', 'l', 'a', 'h'], ['a', 'l'], ['-'], ['a', 'n', 'i'], [','], ['t', 'h', 'e'], ['p', 'r', 'e', 'a', 'c', 'h', 'e', 'r'], ['a', 't'], ['t', 'h', 'e'], ['m', 'o', 's', 'q', 'u', 'e'], ['i', 'n'], ['t', 'h', 'e'], ['t', 'o', 'w', 'n'], ['o', 'f'], ['q', 'a', 'i', 'm'], [','], ['n', 'e', 'a', 'r'], ['t', 'h', 'e'], ['s', 'y', 'r', 'i', 'a', 'n'], ['b', 'o', 'r', 'd', 'e', 'r'], ['.']]\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[0])['chars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'ADJ', 'NOUN', 'VERB', 'PROPN', 'PROPN', 'PROPN', 'PUNCT', 'PROPN', 'PUNCT', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'ADP', 'PROPN', 'PUNCT', 'ADP', 'DET', 'ADJ', 'NOUN', 'PUNCT']\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[0])['udtags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NNP', 'HYPH', 'NNP', ':', 'JJ', 'NNS', 'VBD', 'NNP', 'NNP', 'NNP', 'HYPH', 'NNP', ',', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'NNP', ',', 'IN', 'DT', 'JJ', 'NN', '.']\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[0])['ptbtags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_FREQ = 2\n",
    "\n",
    "WORDS.build_vocab(train_data, \n",
    "                 min_freq = MIN_FREQ,\n",
    "                 vectors = \"glove.6B.100d\", \n",
    "                 unk_init = torch.Tensor.normal_)\n",
    "\n",
    "CHARS.build_vocab(train_data,\n",
    "                  min_freq = MIN_FREQ,\n",
    "                  vectors = \"glove.6B.50d\",\n",
    "                  unk_init = torch.Tensor.normal_)\n",
    "\n",
    "UD_TAGS.build_vocab(train_data)\n",
    "PTB_TAGS.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in WORDS vocabulary: 8866\n",
      "Unique tokens in CHARS vocabulary: 78\n",
      "Unique tokens in UD_TAG vocabulary: 18\n",
      "Unique tokens in PTB_TAG vocabulary: 51\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in WORDS vocabulary: {len(WORDS.vocab)}\")\n",
    "print(f\"Unique tokens in CHARS vocabulary: {len(CHARS.vocab)}\")\n",
    "print(f\"Unique tokens in UD_TAG vocabulary: {len(UD_TAGS.vocab)}\")\n",
    "print(f\"Unique tokens in PTB_TAG vocabulary: {len(PTB_TAGS.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('e', 95341), ('t', 71276), ('a', 66834), ('o', 60181), ('i', 57634), ('n', 55029), ('s', 48772), ('r', 46948), ('h', 38062), ('l', 33300), ('d', 30102), ('u', 22951), ('c', 22852), ('m', 20382), ('y', 16994), ('f', 16355), ('g', 16040), ('p', 15996), ('w', 15814), ('b', 12319), ('.', 11491), ('v', 8567), (',', 7155), ('k', 7150), ('-', 3768), ('0', 3035), (\"'\", 2558), ('1', 1929), ('j', 1652), ('x', 1640), ('2', 1583), ('\"', 1298), ('!', 1221), ('/', 1140), (':', 1092), ('q', 1065), ('3', 1048), (')', 938), ('?', 937), ('(', 866), ('5', 855), ('4', 717), ('z', 704), ('9', 702), ('6', 598), ('7', 597), ('8', 547), ('_', 539), ('=', 369), ('*', 310), ('$', 270), ('@', 177), ('&', 158), ('>', 151), ('<', 143), (';', 109), ('’', 94), ('#', 73), ('+', 54), ('%', 43), ('[', 34), (']', 34), ('“', 30), ('”', 30), ('|', 25), ('~', 17), ('`', 15), ('‘', 13), ('—', 9), ('–', 9), ('^', 8), ('…', 7), ('·', 6), ('{', 4), ('}', 3), ('é', 2), ('ã', 1), ('³', 1), ('á', 1), ('ç', 1), ('\\xad', 1), ('£', 1)]\n"
     ]
    }
   ],
   "source": [
    "print(CHARS.vocab.freqs.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordEncoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 embedding_dim,\n",
    "                 pad_idx):\n",
    "    \n",
    "        super().__init__()\n",
    "    \n",
    "        self.embedding_dim = embedding_dim\n",
    "    \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "    \n",
    "    def forward(self, words):\n",
    "        \n",
    "        #words = [sent len, batch size]\n",
    "        \n",
    "        embedded = self.embedding(words)\n",
    "        \n",
    "        #embedded = [sent len, batch size, emb dim]\n",
    "        \n",
    "        return embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharacterEncoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 embedding_dim,\n",
    "                 filter_size,\n",
    "                 hidden_dim,\n",
    "                 pad_idx):\n",
    "    \n",
    "        super().__init__()\n",
    "        \n",
    "        assert filter_size % 2 == 1, \"Kernel size must be odd!\"\n",
    "        \n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
    "        \n",
    "        self.cnn = nn.Conv1d(in_channels = embedding_dim,\n",
    "                             out_channels = hidden_dim,\n",
    "                             kernel_size = filter_size,\n",
    "                             padding = (filter_size - 1) // 2)\n",
    "        \n",
    "    def forward(self, chars):\n",
    "        \n",
    "        #chars = [batch size, sent len, word len]\n",
    "        \n",
    "        batch_size = chars.shape[0]\n",
    "        sent_len = chars.shape[1]\n",
    "        word_len = chars.shape[2]\n",
    "        \n",
    "        embedded = self.embedding(chars)\n",
    "        \n",
    "        #embedded = [batch size, sent len, char emb dim, word len]\n",
    "        \n",
    "        embedded = embedded.view(-1, word_len, self.embedding_dim)\n",
    "        embedded = embedded.permute(0, 2, 1)\n",
    "        \n",
    "        #embedded = [batch size * sent len, char emb dim, word len]\n",
    "        \n",
    "        embedded = self.cnn(embedded)\n",
    "                \n",
    "        #embedded = [batch size * sent len, hid dim, word len]\n",
    "        \n",
    "        embedded = embedded.view(batch_size, sent_len, self.hidden_dim, word_len)\n",
    "                \n",
    "        #embedded = [batch size, sent len, hid dim, word len]\n",
    "        \n",
    "        embedded = torch.max(embedded, dim = -1).values\n",
    "                \n",
    "        #embeded = [batch size, sent len, hid dim]\n",
    "        \n",
    "        embedded = embedded.permute(1, 0, 2)\n",
    "        \n",
    "        #embedded = [sent len, batch size, hid dim]\n",
    "        \n",
    "        return embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNPOSTagger(nn.Module):\n",
    "    def __init__(self, \n",
    "                 word_encoder,\n",
    "                 char_encoder,\n",
    "                 hidden_dim, \n",
    "                 output_dim, \n",
    "                 n_layers, \n",
    "                 bidirectional, \n",
    "                 dropout):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        assert word_encoder.embedding_dim == char_encoder.hidden_dim\n",
    "        \n",
    "        self.word_encoder = word_encoder\n",
    "        self.char_encoder = char_encoder\n",
    "        \n",
    "        embedding_dim = 2 * word_encoder.embedding_dim\n",
    "        \n",
    "        self.rnn = nn.LSTM(embedding_dim, \n",
    "                           hidden_dim, \n",
    "                           num_layers = n_layers, \n",
    "                           bidirectional = bidirectional)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "          \n",
    "    def forward(self, words, chars):\n",
    "\n",
    "        #words = [sent len, batch size]\n",
    "        #chars = [batch size, sent len, word len]\n",
    "        \n",
    "        words_embedded = self.dropout(self.word_encoder(words))\n",
    "        chars_embedded = self.dropout(self.char_encoder(chars))\n",
    "                \n",
    "        #words_embedded = [sent len, batch size, emb dim]\n",
    "        #chars_embeded = [sent len, batch size, emb dim]\n",
    "        \n",
    "        embedded = torch.cat((chars_embedded, words_embedded), dim = -1)\n",
    "        \n",
    "        #embedded = [sent len, batch size, emb dim * 2]\n",
    "                \n",
    "        outputs, (hidden, cell) = self.rnn(embedded)\n",
    "        \n",
    "        #output = [sent len, batch size, hid dim * n directions]\n",
    "        #hidden/cell = [n layers * n directions, batch size, hid dim]\n",
    "        \n",
    "        predictions = self.fc(self.dropout(outputs))\n",
    "        \n",
    "        #predictions = [sent len, batch size, output dim]\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD_INPUT_DIM = len(WORDS.vocab)\n",
    "WORD_EMBEDDING_DIM = 100\n",
    "WORD_PAD_IDX = WORDS.vocab.stoi[WORDS.pad_token]\n",
    "\n",
    "CHAR_INPUT_DIM = len(CHARS.vocab)\n",
    "CHAR_EMBEDDING_DIM = 50\n",
    "CHAR_CNN_FILTER_SIZE = 3\n",
    "CHAR_PAD_IDX = CHARS.vocab.stoi[CHARS.pad_token]\n",
    "\n",
    "HIDDEN_DIM = 128\n",
    "OUTPUT_DIM = len(UD_TAGS.vocab)\n",
    "N_LAYERS = 2\n",
    "BIDIRECTIONAL = True\n",
    "DROPOUT = 0.25\n",
    "\n",
    "word_encoder = WordEncoder(WORD_INPUT_DIM,\n",
    "                           WORD_EMBEDDING_DIM,\n",
    "                           WORD_PAD_IDX)\n",
    "\n",
    "char_encoder = CharacterEncoder(CHAR_INPUT_DIM,\n",
    "                                CHAR_EMBEDDING_DIM,\n",
    "                                CHAR_CNN_FILTER_SIZE,\n",
    "                                WORD_EMBEDDING_DIM,\n",
    "                                CHAR_PAD_IDX)\n",
    "\n",
    "model = RNNPOSTagger(word_encoder,\n",
    "                     char_encoder,\n",
    "                     HIDDEN_DIM, \n",
    "                     OUTPUT_DIM, \n",
    "                     N_LAYERS, \n",
    "                     BIDIRECTIONAL, \n",
    "                     DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNPOSTagger(\n",
       "  (word_encoder): WordEncoder(\n",
       "    (embedding): Embedding(8866, 100, padding_idx=1)\n",
       "  )\n",
       "  (char_encoder): CharacterEncoder(\n",
       "    (embedding): Embedding(78, 50, padding_idx=1)\n",
       "    (cnn): Conv1d(50, 100, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "  )\n",
       "  (rnn): LSTM(200, 128, num_layers=2, bidirectional=True)\n",
       "  (fc): Linear(in_features=256, out_features=18, bias=True)\n",
       "  (dropout): Dropout(p=0.25, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.normal_(param.data, mean=0, std=0.1)\n",
    "        \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 1,643,410 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8866, 100])\n"
     ]
    }
   ],
   "source": [
    "pretrained_word_embeddings = WORDS.vocab.vectors\n",
    "\n",
    "print(pretrained_word_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([78, 50])\n"
     ]
    }
   ],
   "source": [
    "pretrained_char_embeddings = CHARS.vocab.vectors\n",
    "\n",
    "print(pretrained_char_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0519,  0.7052,  0.8600,  ...,  0.0044, -2.0071, -0.0570],\n",
       "        [-1.2102, -0.9203,  0.1332,  ...,  1.9241,  0.7073,  1.3111],\n",
       "        [ 0.7383,  0.6545,  1.0873,  ..., -0.1680,  0.6562,  1.1014],\n",
       "        ...,\n",
       "        [-0.4286,  1.0551,  0.6042,  ..., -0.0753, -0.1357,  0.6105],\n",
       "        [-0.6707,  0.6986,  0.6963,  ...,  0.0801,  0.1009,  0.9292],\n",
       "        [-0.1443,  0.1088, -0.5041,  ...,  0.2690,  1.1543,  1.0493]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_encoder.embedding.weight.data.copy_(pretrained_word_embeddings)\n",
    "char_encoder.embedding.weight.data.copy_(pretrained_char_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
      "        ...,\n",
      "        [ 0.9261,  2.3049,  0.5502,  ..., -0.3492, -0.5298, -0.1577],\n",
      "        [-0.5972,  0.0471, -0.2406,  ..., -0.9446, -0.1126, -0.2260],\n",
      "        [-0.4809,  2.5629,  0.9530,  ...,  0.5278, -0.4588,  0.7294]])\n"
     ]
    }
   ],
   "source": [
    "WORD_UNK_IDX = WORDS.vocab.stoi[WORDS.unk_token]\n",
    "\n",
    "word_encoder.embedding.weight.data[WORD_UNK_IDX] = torch.zeros(WORD_EMBEDDING_DIM)\n",
    "word_encoder.embedding.weight.data[WORD_PAD_IDX] = torch.zeros(WORD_EMBEDDING_DIM)\n",
    "\n",
    "print(word_encoder.embedding.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.7383,  0.6545,  1.0873,  ..., -0.1680,  0.6562,  1.1014],\n",
      "        ...,\n",
      "        [-0.4286,  1.0551,  0.6042,  ..., -0.0753, -0.1357,  0.6105],\n",
      "        [-0.6707,  0.6986,  0.6963,  ...,  0.0801,  0.1009,  0.9292],\n",
      "        [-0.1443,  0.1088, -0.5041,  ...,  0.2690,  1.1543,  1.0493]])\n"
     ]
    }
   ],
   "source": [
    "CHAR_UNK_IDX = CHARS.vocab.stoi[CHARS.unk_token]\n",
    "\n",
    "char_encoder.embedding.weight.data[CHAR_UNK_IDX] = torch.zeros(CHAR_EMBEDDING_DIM)\n",
    "char_encoder.embedding.weight.data[CHAR_PAD_IDX] = torch.zeros(CHAR_EMBEDDING_DIM)\n",
    "\n",
    "print(char_encoder.embedding.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG_PAD_IDX = UD_TAGS.vocab.stoi[UD_TAGS.pad_token]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_accuracy(preds, y, tag_pad_idx):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
    "    non_pad_elements = (y != tag_pad_idx).nonzero()\n",
    "    correct = max_preds[non_pad_elements].squeeze(1).eq(y[non_pad_elements])\n",
    "    return correct.sum() / torch.FloatTensor([y[non_pad_elements].shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, tag_pad_idx):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        words = batch.words\n",
    "        chars = batch.chars\n",
    "        tags = batch.udtags\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #words = [sent len, batch size]\n",
    "        #chars = [batch size, sent len, word len]\n",
    "        \n",
    "        predictions = model(words, chars)\n",
    "        \n",
    "        #predictions = [sent len, batch size, output dim]\n",
    "        #tags = [sent len, batch size]\n",
    "        \n",
    "        predictions = predictions.view(-1, predictions.shape[-1])\n",
    "        tags = tags.view(-1)\n",
    "        \n",
    "        #predictions = [sent len * batch size, output dim]\n",
    "        #tags = [sent len * batch size]\n",
    "        \n",
    "        loss = criterion(predictions, tags)\n",
    "                \n",
    "        acc = categorical_accuracy(predictions, tags, tag_pad_idx)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion, tag_pad_idx):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for batch in iterator:\n",
    "\n",
    "            words = batch.words\n",
    "            chars = batch.chars\n",
    "            tags = batch.udtags\n",
    "            \n",
    "            predictions = model(words, chars)\n",
    "            \n",
    "            predictions = predictions.view(-1, predictions.shape[-1])\n",
    "            tags = tags.view(-1)\n",
    "            \n",
    "            loss = criterion(predictions, tags)\n",
    "            \n",
    "            acc = categorical_accuracy(predictions, tags, tag_pad_idx)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 10s\n",
      "\tTrain Loss: 0.806 | Train Acc: 74.70%\n",
      "\t Val. Loss: 0.402 |  Val. Acc: 87.24%\n",
      "Epoch: 02 | Epoch Time: 0m 10s\n",
      "\tTrain Loss: 0.281 | Train Acc: 91.07%\n",
      "\t Val. Loss: 0.315 |  Val. Acc: 89.61%\n",
      "Epoch: 03 | Epoch Time: 0m 10s\n",
      "\tTrain Loss: 0.213 | Train Acc: 93.18%\n",
      "\t Val. Loss: 0.289 |  Val. Acc: 90.80%\n",
      "Epoch: 04 | Epoch Time: 0m 10s\n",
      "\tTrain Loss: 0.177 | Train Acc: 94.26%\n",
      "\t Val. Loss: 0.268 |  Val. Acc: 91.32%\n",
      "Epoch: 05 | Epoch Time: 0m 10s\n",
      "\tTrain Loss: 0.153 | Train Acc: 95.01%\n",
      "\t Val. Loss: 0.250 |  Val. Acc: 91.89%\n",
      "Epoch: 06 | Epoch Time: 0m 10s\n",
      "\tTrain Loss: 0.134 | Train Acc: 95.65%\n",
      "\t Val. Loss: 0.247 |  Val. Acc: 92.18%\n",
      "Epoch: 07 | Epoch Time: 0m 10s\n",
      "\tTrain Loss: 0.120 | Train Acc: 96.06%\n",
      "\t Val. Loss: 0.244 |  Val. Acc: 92.42%\n",
      "Epoch: 08 | Epoch Time: 0m 10s\n",
      "\tTrain Loss: 0.107 | Train Acc: 96.51%\n",
      "\t Val. Loss: 0.233 |  Val. Acc: 93.01%\n",
      "Epoch: 09 | Epoch Time: 0m 10s\n",
      "\tTrain Loss: 0.098 | Train Acc: 96.76%\n",
      "\t Val. Loss: 0.241 |  Val. Acc: 92.48%\n",
      "Epoch: 10 | Epoch Time: 0m 10s\n",
      "\tTrain Loss: 0.090 | Train Acc: 97.00%\n",
      "\t Val. Loss: 0.245 |  Val. Acc: 92.63%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, TAG_PAD_IDX)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion, TAG_PAD_IDX)\n",
    "    \n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut2-model.pt')\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.244 |  Test Acc: 92.68%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(model, test_iterator, criterion, TAG_PAD_IDX)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} |  Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "def tag_sentence(model, device, sentence, word_vocab, char_vocab, tag_vocab):\n",
    "    \n",
    "    if isinstance(sentence, str):\n",
    "        nlp = spacy.load('en')\n",
    "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "\n",
    "    numericalized_words = [word_vocab.stoi[t] for t in tokens]\n",
    "\n",
    "    unks = [t for t, n in zip(tokens, numericalized_words) if n == 0]\n",
    "        \n",
    "    chars = [list(t) for t in tokens]\n",
    "    char_len = max([len(c) for c in chars])\n",
    "    chars = [c + ['<pad>'] * (char_len - len(c)) for c in chars]\n",
    "    \n",
    "\n",
    "    numericalized_chars = [[char_vocab.stoi[i] for i in c] for c in chars]\n",
    "    \n",
    "    word_tensor = torch.LongTensor(numericalized_words)\n",
    "    char_tensor = torch.LongTensor(numericalized_chars)\n",
    "    \n",
    "    word_tensor = word_tensor.unsqueeze(-1).to(device)\n",
    "    char_tensor = char_tensor.unsqueeze(0).to(device)\n",
    "    \n",
    "    model.eval()\n",
    "     \n",
    "    predictions = model(word_tensor, char_tensor)\n",
    "    \n",
    "    top_predictions = predictions.argmax(-1)\n",
    "    \n",
    "    predicted_tags = [tag_vocab.itos[t.item()] for t in top_predictions]\n",
    "    \n",
    "    return tokens, predicted_tags, unks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'moi', 'in', 'iraq', 'is', 'equivalent', 'to', 'the', 'us', 'fbi', ',', 'so', 'this', 'would', 'be', 'like', 'having', 'j.', 'edgar', 'hoover', 'unwittingly', 'employ', 'at', 'a', 'high', 'level', 'members', 'of', 'the', 'weathermen', 'bombers', 'back', 'in', 'the', '1960s', '.']\n"
     ]
    }
   ],
   "source": [
    "example_index = 4\n",
    "\n",
    "sentence = vars(train_data.examples[example_index])['words']\n",
    "actual_tags = vars(train_data.examples[example_index])['udtags']\n",
    "\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['moi', 'edgar', 'hoover', 'unwittingly', 'weathermen']\n"
     ]
    }
   ],
   "source": [
    "tokens, pred_tags, unks = tag_sentence(model, device, sentence, WORDS.vocab, CHARS.vocab, UD_TAGS.vocab)\n",
    "\n",
    "print(unks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred. Tag\tActual Tag\tCorrect?\tToken\n",
      "\n",
      "DET\t\tDET\t\t✔\t\tthe\n",
      "NOUN\t\tPROPN\t\t✘\t\tmoi\n",
      "ADP\t\tADP\t\t✔\t\tin\n",
      "PROPN\t\tPROPN\t\t✔\t\tiraq\n",
      "AUX\t\tAUX\t\t✔\t\tis\n",
      "ADJ\t\tADJ\t\t✔\t\tequivalent\n",
      "ADP\t\tADP\t\t✔\t\tto\n",
      "DET\t\tDET\t\t✔\t\tthe\n",
      "PROPN\t\tPROPN\t\t✔\t\tus\n",
      "PROPN\t\tPROPN\t\t✔\t\tfbi\n",
      "PUNCT\t\tPUNCT\t\t✔\t\t,\n",
      "ADV\t\tADV\t\t✔\t\tso\n",
      "PRON\t\tPRON\t\t✔\t\tthis\n",
      "AUX\t\tAUX\t\t✔\t\twould\n",
      "VERB\t\tVERB\t\t✔\t\tbe\n",
      "SCONJ\t\tSCONJ\t\t✔\t\tlike\n",
      "VERB\t\tVERB\t\t✔\t\thaving\n",
      "PROPN\t\tPROPN\t\t✔\t\tj.\n",
      "PROPN\t\tPROPN\t\t✔\t\tedgar\n",
      "PROPN\t\tPROPN\t\t✔\t\thoover\n",
      "ADV\t\tADV\t\t✔\t\tunwittingly\n",
      "VERB\t\tVERB\t\t✔\t\temploy\n",
      "ADP\t\tADP\t\t✔\t\tat\n",
      "DET\t\tDET\t\t✔\t\ta\n",
      "ADJ\t\tADJ\t\t✔\t\thigh\n",
      "NOUN\t\tNOUN\t\t✔\t\tlevel\n",
      "NOUN\t\tNOUN\t\t✔\t\tmembers\n",
      "ADP\t\tADP\t\t✔\t\tof\n",
      "DET\t\tDET\t\t✔\t\tthe\n",
      "PROPN\t\tPROPN\t\t✔\t\tweathermen\n",
      "NOUN\t\tNOUN\t\t✔\t\tbombers\n",
      "ADV\t\tADV\t\t✔\t\tback\n",
      "ADP\t\tADP\t\t✔\t\tin\n",
      "DET\t\tDET\t\t✔\t\tthe\n",
      "NOUN\t\tNOUN\t\t✔\t\t1960s\n",
      "PUNCT\t\tPUNCT\t\t✔\t\t.\n"
     ]
    }
   ],
   "source": [
    "print(\"Pred. Tag\\tActual Tag\\tCorrect?\\tToken\\n\")\n",
    "\n",
    "for token, pred_tag, actual_tag in zip(tokens, pred_tags, actual_tags):\n",
    "    correct = '✔' if pred_tag == actual_tag else '✘'\n",
    "    print(f\"{pred_tag}\\t\\t{actual_tag}\\t\\t{correct}\\t\\t{token}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "sentence = 'The Queen will deliver a speech about the conflict in North Korea at 1pm tomorrow.'\n",
    "\n",
    "tokens, tags, unks = tag_sentence(model, device, sentence, WORDS.vocab, CHARS.vocab, UD_TAGS.vocab)\n",
    "\n",
    "print(unks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred. Tag\tToken\n",
      "\n",
      "DET\t\tthe\n",
      "NOUN\t\tqueen\n",
      "AUX\t\twill\n",
      "VERB\t\tdeliver\n",
      "DET\t\ta\n",
      "NOUN\t\tspeech\n",
      "ADP\t\tabout\n",
      "DET\t\tthe\n",
      "NOUN\t\tconflict\n",
      "ADP\t\tin\n",
      "PROPN\t\tnorth\n",
      "PROPN\t\tkorea\n",
      "ADP\t\tat\n",
      "NUM\t\t1\n",
      "NOUN\t\tpm\n",
      "NOUN\t\ttomorrow\n",
      "PUNCT\t\t.\n"
     ]
    }
   ],
   "source": [
    "print(\"Pred. Tag\\tToken\\n\")\n",
    "\n",
    "for token, tag in zip(tokens, tags):\n",
    "    print(f\"{tag}\\t\\t{token}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
